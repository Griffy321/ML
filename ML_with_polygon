# It takes about 5 minutes to finish running so dont worry if you think its in a loop
from polygon import RESTClient
from typing import cast
from urllib3 import HTTPResponse
import pandas as pd
import json
import lightgbm as lgb
from sklearn.metrics import mean_squared_error
import backtrader as bt
import numpy as np
from sklearn.preprocessing import StandardScaler
import pandas_ta as ta

api_key = 'your_api_key'

client = RESTClient(api_key)

# Fetch the data
aggs = cast(
    HTTPResponse,
    client.get_aggs(
        'TSLA',  
        1,
        'minute',
        '2024-05-01',
        '2024-05-31',
        raw=True
    ),
)

poly_data = json.loads(aggs.data)
poly_data = poly_data['results']

# Check the length of the data to ensure full period coverage
print(f"Number of data points fetched: {len(poly_data)}")

# Prepare the data for DataFrame
dates = []
open_prices = []
high_prices = []
low_prices = []
close_prices = []
volumes = []

for bar in poly_data:
    dates.append(pd.Timestamp(bar['t'], tz='GMT', unit='ms'))
    open_prices.append(bar['o'])
    high_prices.append(bar['h'])
    low_prices.append(bar['l'])
    close_prices.append(bar['c'])
    volumes.append(bar['v'])

data = {
    'Open': open_prices,
    'High': high_prices,
    'Low': low_prices,
    'Close': close_prices,
    'Volume': volumes
}

dataFrame = pd.DataFrame(data, index=dates)

# Preprocessing
dataFrame['Returns'] = dataFrame['Close'].pct_change()
dataFrame.dropna(inplace=True)

# Creating lagged features
for lag in range(1, 6):
    dataFrame[f'Lag_{lag}'] = dataFrame['Returns'].shift(lag)
dataFrame.dropna(inplace=True)

# Adding new technical indicators

# Handle VIDYA's potential dtype issue
dataFrame['VIDYA'] = ta.vidya(dataFrame['Close'], length=14).astype(float)

# Calculate Donchian Channels and inspect the result
donchian = ta.donchian(dataFrame['High'], dataFrame['Low'], lower_length=20, upper_length=20)
print("Donchian Channel Output:\n", donchian.head())  # Inspect the columns to identify the correct names

# Use the correct column names for Donchian Channels
dataFrame['Donchian_Upper'] = donchian.iloc[:, 0].shift(1)  # Assuming the first column is Upper
dataFrame['Donchian_Lower'] = donchian.iloc[:, 1].shift(1)  # Assuming the second column is Lower

# RSI and Choppiness Index
dataFrame['RSI'] = ta.rsi(dataFrame['Close'], length=14)
dataFrame['Choppiness'] = ta.chop(dataFrame['High'], dataFrame['Low'], dataFrame['Close'], length=14)
dataFrame.dropna(inplace=True)

# Prepare data for rolling window
X = dataFrame[['Lag_1', 'Lag_2', 'Lag_3', 'Lag_4', 'Lag_5', 'VIDYA', 'Donchian_Upper', 'Donchian_Lower', 'RSI', 'Choppiness']]
y = dataFrame['Returns']

# Standardize features
scaler = StandardScaler()
X_scaled = pd.DataFrame(scaler.fit_transform(X), columns=X.columns, index=X.index)

# Rolling window parameters
window_size = 500  # size of the training window
predictions = []

# Initialize LightGBM parameters
params = {
    'objective': 'regression',
    'metric': 'mse',
    'boosting_type': 'gbdt',
    'num_leaves': 31,
    'learning_rate': 0.05,
    'feature_fraction': 0.9
}

# Rolling window training and prediction
for i in range(window_size, len(dataFrame)):
    X_train = X_scaled.iloc[i-window_size:i]
    y_train = y.iloc[i-window_size:i]
    X_test = X_scaled.iloc[i:i+1]
    
    lgb_train = lgb.Dataset(X_train, label=y_train)
    
    model = lgb.train(
        params,
        lgb_train,
        num_boost_round=100
    )
    
    y_pred = model.predict(X_test, num_iteration=model.best_iteration)
    predictions.append(y_pred[0])

# Add predictions to the DataFrame
dataFrame['Prediction'] = np.nan
dataFrame.iloc[window_size:, dataFrame.columns.get_loc('Prediction')] = predictions

# Extend PandasData to include 'Prediction'
class PandasDataExtend(bt.feeds.PandasData):
    lines = ('prediction',)
    params = (('prediction', -1),)

# Add the strategy
class MLStrategy(bt.Strategy):
    def __init__(self):
        self.data_close = self.datas[0].close
        self.pred = self.datas[0].prediction
        self.order = None

    def next(self):
        if not np.isnan(self.pred[0]):
            if self.order:
                return
            
            if self.pred[0] > 0:
                self.order = self.buy()
                print(f'Buy Order: {self.data.datetime.datetime(0)}')
            elif self.pred[0] < 0:
                self.order = self.sell()
                print(f'Sell Order: {self.data.datetime.datetime(0)}')

    def notify_order(self, order):
        if order.status in [order.Completed, order.Canceled, order.Margin]:
            self.order = None

# Run backtesting
cerebro = bt.Cerebro()

# Set broker commission
cerebro.broker.setcommission(commission=0.0005)

data_bt = PandasDataExtend(dataname=dataFrame)
cerebro.adddata(data_bt)
cerebro.addstrategy(MLStrategy)
cerebro.run()
cerebro.plot()
